---
type: slides
---

# モデルのトレーニングと更新

Notes: 
この最終章では、最新のNLPの素晴らしい側面の1つであるモデルのトレーニングについて紹介します！
このレッスンでは固有表現抽出器にフォーカスし、spaCyのニューラルネットワークモデルのトレーニングと必要なデータについて学んでいきます。

---

# なぜモデルをアップデートするか？

- 特定のドメインでより良い結果が得られます
- 問題に特化した分類スキームを学習できます
- テキストの分類に必須です
- 固有表現抽出に非常に便利です
- 品詞タグ付けや依存性解析については重要性が低いです

Notes: やり方の説明を始める前に、自問自答してみましょう。なぜ私たちは自分のデータでモデルを更新したいのでしょうか？なぜ事前に訓練されたモデルを使うだけではダメなのでしょうか？

統計モデルは、訓練された例に基づいて予測を行います。

通常、適用するドメインの例を示すことで、モデルの予測をより正確にできます。

また、問題に固有のカテゴリを予測したい場合がよくあり、モデルはその新しいカテゴリについて学習する必要があります。

モデルのアップデートはテキスト分類には必須で、固有表現抽出には非常に有用ですが、タグ付けや構文解析にはそれほど重要ではありません。

---

# トレーニングはどのように行われるか(1)

1. モデルの重みをランダムに `nlp.begin_training` で**初期化**します
2. `nlp.update` を呼び出して、現在の重みでいくつかの例を**予測**します
3. 予測値と真のラベルを**比較**します
4. 予測を改善するため、重みの変更方法を**計算**します
5. 重みを少し**更新**します
6. 2に戻ります

Notes: spaCyは、新たなデータによる既存のモデル更新や、新しいモデルの学習をサポートしています。

事前に学習されたモデルを使わない場合は、まずランダムに重みを初期化します。

次に、`nlp.update` を呼び出します。これは現在の重みでバッチデータを予測します。

次に、予測結果を正解と照合し、より良い予測ができるような重みの変更方法を計算します。

最後に、現在の重みを少し更新して、次のバッチデータにうつります。

データの各バッチに対して `nlp.update` を呼び出し続けます。

---

# トレーニングはどのように行われるか(2)

<img src="/training.png" alt="トレーニングプロセスのダイアグラム" />

- **学習データ:** データとそのアノテーション
- **テキスト:** モデルがラベルを予測する入力データ
- **ラベル:** モデルが予測するラベル
- **勾配:** 重みの変更方法

Notes: ここに、処理の図を示します。

学習データは、モデルを更新するもととなるデータです。

テキストは、文章、段落、またはより長い文章です。良い結果を得るためには、モデルを実際に適用するデータと似たものを用いる必要があります。

ラベルはモデルに予測させものです。テキストのカテゴリ、または固有表現のスパンとそのタイプなどが当てはまります。

勾配は、予測と正解の誤差を減らすためのモデルの変更方法を示します。予測ラベルと正解ラベルを比較するときに計算されます。

学習後、更新されたモデルを保存して、アプリケーションで使用することができます。

---

# 例: 固有表現抽出器の更新

- 固有表現抽出器は、文脈に応じて単語やフレーズをタグ付けします
- 各トークンは1つの固有表現の一部にしかなり得ません
- データは文脈に沿ったものである必要があります

```python
("iPhone X is coming", {"entities": [(0, 8, "GADGET")]})
```

- 固有表現のないテキストも重要です

```python
("I need a new phone! Any tips?", {"entities": []})
```

- **Goal:** モデルを汎化させる

Notes: ここでは、固有表現抽出器の例を見てみましょう。

固有表現抽出器は、Docを受け取り、フレーズとそのラベルを予測します。
つまり訓練データには、テキスト、それらに含まれる固有表現、そのラベルが含まれている必要があります。

固有表現は重複することができないため、各トークンは1つの固有表現の一部にしかなりません。

固有表現抽出器は文脈を見て固有表現を予測するため、固有表現とその周囲の文脈についても訓練する必要があります。

最も簡単な方法は、モデルにテキストと文字オフセットのリストを渡すことです。
例えば、「iPhone X」はガジェットで、0文字目で始まり8文字目で終わります。

固有表現ではない単語を学習することも非常に重要です。

この場合、アノテーションのリストは空になります。

私たちの目標は、たとえ学習データになかったとしても、似たような文脈で新しい固有表現を抽出するようにモデルを学習させることです。

---

# 学習データ

- モデルが文脈を見て予測してほしいことの例
- **既存モデル**の更新：数百から数千の例
- **新しいカテゴリ**のトレーニング：数千から数百万の例
  - spaCyの英語モデル：200万語
- 通常は人間のアノテータが手動で作成
- 半自動化することができます。例えば、spaCyの `Matcher` を使用してください！

Notes: 学習データを用いて、モデルに予測させたいことを伝えます。これには、認識したいテキストや固有表現、あるいはトークンとその正しい品詞タグなどがあります。

既存のモデルを更新するには、数百から数千のデータが必要です。

新しいカテゴリを訓練するには、数百万程度必要なこともあります。

spaCyの事前学習の英語のモデルは、品詞タグと依存関係と固有固有表現のついた200万語のデータで訓練されています。

訓練データは通常、人間によって作成されます。

これは大変な作業です。しかし、半自動化することができます。
例えば、spaCyの `Matcher`を使用します。

---

# Let's practice!

Notes: さて、いよいよ学習データの準備に取り掛かりましょう。いくつかの例を見て、新しい固有表現タイプの小さなデータセットを作成してみましょう。
