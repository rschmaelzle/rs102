---
type: slides
---

# トレーニングループ

Notes: 他のライブラリではモデルのトレーニングを行うメソッドを1つだけ提供しているかもしれませんが、 spaCyではトレーニングループを完全に制御することができます。

---

# トレーニングループのステップ

1. 何回も**ループ**します
2. トレーニングデータを**シャッフル**します
3. データをバッチに**分割**します
4. それぞれのバッチに対してモデルを**更新**します
5. 更新されたモデルを**保存**します

Notes: トレーニングループは、モデルを訓練または更新するために実行される一連のステップです。

通常、モデルが効果的に学習できるように複数回反復するので、何回か実行する必要があります。
10回の反復訓練をしたい場合、10回ループする必要があります。

モデルが局所最適解から抜け出せなくなるのを防ぐために、反復ごとにランダムにデータをシャッフルします。
これは確率的勾配降下を行うときによく使われる手法です。

次に、学習データをいくつかの例のバッチに分割（ミニバッチ化）します。これにより、勾配のより正確な推定ができます。

最後に、各バッチごとにモデルを更新し、反復が終わるまでループを回します。

そして、モデルをディレクトリに保存して、spaCyで使用できるようにします。

---

# 要約：トレーニングの仕組み

<img src="/training.png" alt="トレーニングプロセスのダイアグラム" />

- **トレーニングデータ:** データ例とアノテーション
- **テキスト:** モデルがラベルを予測すべき入力データ
- **ラベル:** モデルが予測するラベル
- **勾配:** モデルの重みの変更方法

Notes: 要約:

学習データは、モデルを更新するもととなるデータです。

テキストは、文章、段落、またはより長い文章です。良い結果を得るためには、モデルを実際に適用するデータと似たものを用いる必要があります。

ラベルはモデルに予測させものです。テキストのカテゴリ、または固有表現のスパンとそのタイプなどが当てはまります。

勾配は、予測と正解の誤差を減らすための、モデルの変更方法を示します。予測ラベルと正解ラベルを比較するときに計算されます。

---

# ループの例

```python
TRAINING_DATA = [
    ("How to preorder the iPhone X", {"entities": [(20, 28, "GADGET")]})
    # たくさんのデータ、、、
]
```

```python
# 10回ループする
for i in range(10):
    # トレーニングデータをシャッフルする
    random.shuffle(TRAINING_DATA)
    # バッチを作成し、反復処理する
    for batch in spacy.util.minibatch(TRAINING_DATA):
        # テキストとアノテーションのバッチを分割する
        texts = [text for text, annotation in batch]
        annotations = [annotation for text, annotation in batch]
        # モデルを更新する
        nlp.update(texts, annotations)

# モデルを保存する
nlp.to_disk(path_to_model)
```

Notes: ここに例を示します。

テキストと固有表現アノテーションからなる学習データのリストがあるとします。

10回の反復処理を行いたいので、`range(10)`で反復処理を行います。

次に、学習データをランダムにシャッフルするために `random` パッケージを用います。

次に、spaCyの `minibatch` ユーティリティ関数を用いてデータをバッチに分割します。

各バッチにおいて、テキストとアノテーションを取得し、モデルを更新するために `nlp.update` メソッドを呼び出します。

最後に、学習したモデルをディレクトリに保存するために `nlp.to_disk` メソッドを呼び出します。

---

# 既存のモデルを更新

- 新しいデータで予測を改善します
- 特に、`"PERSON"`のような既存のカテゴリを改善するのに便利です
- 新しいカテゴリの追加も可能です
- モデルが古いものを「忘れてしまう」ことがないように気をつけましょう

Notes: spaCyを使用すると、追加のデータで既存の事前学習済みモデルを更新することができます。例えば、異なるテキスト上での予測を改善するために便利です。

これは、モデルがすでに知っているカテゴリを改善したい場合に特に便利です。

また、モデルを更新して新しいカテゴリを追加することもできます。

ただ、常に新しいカテゴリの例と、以前に正しく予測した他のカテゴリの例の両方で更新してください。
そうしないと、新しいカテゴリを追加したせいで、既存のカテゴリの性能が落ちる場合があります。

---

# 新しいパイプラインをゼロから作る

```python
# 空の英語モデルを作る
nlp = spacy.blank("en")
# 新しい固有表現抽出器を作り、パイプライに追加する
ner = nlp.create_pipe("ner")
nlp.add_pipe(ner)
# 新しいラベルを追加する
ner.add_label("GADGET")

# トレーニング開始
nlp.begin_training()
# 10回反復する
for itn in range(10):
    random.shuffle(examples)
    # データをバッチに分割する
    for batch in spacy.util.minibatch(examples, size=2):
        texts = [text for text, annotation in batch]
        annotations = [annotation for text, annotation in batch]
        # モデルを更新する
        nlp.update(texts, annotations)
```

Notes: この例ではまず `spacy.blank` メソッドを使用して空の英語モデルを作成します。空のモデルにはパイプラインコンポーネントはなく、言語データとトークン化ルールだけ入っています。

次に、新しい固有表現抽出器を作成してパイプラインに追加します。

`add_label`メソッドを使って、新しいラベルをモデルに追加することができます。

その後、`nlp.begin_training` を呼び出して、ランダムな重みでモデルを初期化することができます。

より良い精度を得るために、データを複数回ループさせ、各ループでランダムにデータをシャッフルするようにします。

各ループでは、spaCyの `minibatch` ユーティリティ関数を用いてデータをバッチに分割します。各データはテキストとその注釈で構成されています。

最後に、テキストとアノテーションでモデルを更新し、ループを続けます。

---

# Let's practice!

Notes: 練習の時間です！トレーニングループの実装方法を見たので、前回の練習で作成したデータを使ってモデルを更新してみましょう。
